---
title: "K-Nearest Neighbors Machine Leaning Model \U0001F4BB \U0001F9E0"
jupyter: python3
---


---



## Import Data/Libraries

```{python}
#| colab: {base_uri: 'https://localhost:8080/'}
!pip3 install lets-plot
```

```{python}

# needed libraries for KNN models
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score
from sklearn.model_selection import cross_val_score,  train_test_split , KFold
from sklearn.preprocessing import StandardScaler, Normalizer
import lets_plot as lp
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns


# foundation dataset
from sklearn.datasets import load_iris

# stretch dataset
cleveland_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', header=None)
hungarian_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data', header=None)
switzerland_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.switzerland.data', header=None)
```

```{python}
#| colab: {base_uri: 'https://localhost:8080/', height: 206}
# Code to set up access to the foundational dataset
iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target_names[iris.target]
# iris_df is now the dataframe to be used for the foundational model
iris_df.head()
```

## Explore, Visualize and Understand the Data

```{python}
#| colab: {base_uri: 'https://localhost:8080/', height: 1000}

sns.pairplot(iris_df, hue = "target", size=3, markers=["o", "s", "D"])
plt.figure()
plt.show()
```

## Feature Enginnering and Data Augmentation

### **Data Augmentation**  
**Definition:**
Data augmentation is the process of artificially expanding the size and diversity of a training dataset by applying transformations or modifications to the existing data while preserving the underlying labels or structure. It is commonly used in machine learning, especially in computer vision and natural language processing, to improve model performance and robustness.

### **Feature Engineering**  
**Definition:**
Feature engineering is the process of creating, modifying, or selecting relevant features (input variables) from raw data to improve the performance of a machine learning model. It involves transforming raw data into a format that makes it more suitable for algorithms to learn patterns.

## Machine Learning Model

### Split the data

```{python}
x= iris_df.drop(columns=['target'])
y = iris_df['target']
```

```{python}
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2) #Training 80% and testing 20%
```

```{python}
#| colab: {base_uri: 'https://localhost:8080/', height: 241}
y.head()
```

### Create the model

```{python}
#| colab: {base_uri: 'https://localhost:8080/', height: 80}
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(x, y)
```

### Train the model

```{python}
#| colab: {base_uri: 'https://localhost:8080/', height: 80}
neigh.fit(x, y)
```

### Make predictions

```{python}
y_pred = neigh.predict(X_test)
```

## Evaluate the Model

```{python}
#| colab: {base_uri: 'https://localhost:8080/'}
accuracy = accuracy_score(y_test, y_pred)*100

print('Accuracy: ' + str(round(accuracy, 2)) + ' %.')
```

