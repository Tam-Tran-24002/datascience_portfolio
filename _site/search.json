[
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Physicist, Mathematician, Cambridge professor.\n\nisaac@applesdofall.org | My wikipedia page\n\n\n\nStanding on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples.\n\n\n\n\n1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow\n\n\n\n\n2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France\n\n\n\n\n\n\n1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001\n\n\n\n\n1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "250_Projects/project2.html",
    "href": "250_Projects/project2.html",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "",
    "text": "Our analysis reveals that weather delays are the most significant across major airports, with San Francisco International (SFO) and Chicago O’Hare International (ORD) being the hardest hit. September is the best month to fly, with the lowest proportion of delayed flights, ensuring smoother travel experiences for passengers.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/mpg/mpg.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "250_Projects/project2.html#elevator-pitch",
    "href": "250_Projects/project2.html#elevator-pitch",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "",
    "text": "Our analysis reveals that weather delays are the most significant across major airports, with San Francisco International (SFO) and Chicago O’Hare International (ORD) being the hardest hit. September is the best month to fly, with the lowest proportion of delayed flights, ensuring smoother travel experiences for passengers.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/mpg/mpg.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-1",
    "href": "250_Projects/project2.html#questiontask-1",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 1",
    "text": "Question|Task 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nTo ensure consistency in the dataset, I replaced all varied missing data types with “NaN”. This involved converting all missing values to the string “NaN”. Here’s an example of one record from the updated dataset:\n\n\nRead and format data\n# Include and execute your code here\nimport pandas as pd\nimport numpy as np\nfrom lets_plot import *\n\nLetsPlot.setup_html(isolated_frame=True)\n\n# Load the data from the URL to the Json file\nurl_flights = 'https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json'\ndf = pd.read_json(url_flights)\n\n\n\n\nRead and format data\n# Include and execute your code here\n#| label: Q1\n#| code-summary: Read and format data for missing values in Task 1\n\nimport pandas as pd\nimport numpy as np\nfrom lets_plot import *\n\nLetsPlot.setup_html(isolated_frame=True)\n\n# Load the data\nurl_flights = 'https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json'\ndf = pd.read_json(url_flights)\n\n# Replace various representations of missing data with NaN\ndf.replace([-999, \"1500+\", \"n/a\", None, \"\", np.nan], \"NaN\", inplace=True)\n\n# Sort the dataframe based on the \"month\" column in ascending order and select the first 5 rows\ndata = df.sort_values(\"month\", ascending=True).head(5)\n\n# Convert to JSON format\njson_data = data.to_json(orient=\"records\", indent=4)\nprint(json_data)\n\n\n[\n    {\n        \"airport_code\":\"ATL\",\n        \"airport_name\":\"Atlanta, GA: Hartsfield-Jackson Atlanta International\",\n        \"month\":\"April\",\n        \"year\":\"NaN\",\n        \"num_of_flights_total\":32891,\n        \"num_of_delays_carrier\":\"NaN\",\n        \"num_of_delays_late_aircraft\":1826,\n        \"num_of_delays_nas\":1841,\n        \"num_of_delays_security\":7,\n        \"num_of_delays_weather\":299,\n        \"num_of_delays_total\":5796,\n        \"minutes_delayed_carrier\":120428.0,\n        \"minutes_delayed_late_aircraft\":104761,\n        \"minutes_delayed_nas\":60284.0,\n        \"minutes_delayed_security\":329,\n        \"minutes_delayed_weather\":19987,\n        \"minutes_delayed_total\":305789\n    },\n    {\n        \"airport_code\":\"ORD\",\n        \"airport_name\":\"Chicago, IL: Chicago O'Hare International\",\n        \"month\":\"April\",\n        \"year\":2010.0,\n        \"num_of_flights_total\":25754,\n        \"num_of_delays_carrier\":\"708\",\n        \"num_of_delays_late_aircraft\":1358,\n        \"num_of_delays_nas\":2185,\n        \"num_of_delays_security\":8,\n        \"num_of_delays_weather\":67,\n        \"num_of_delays_total\":4323,\n        \"minutes_delayed_carrier\":50594.0,\n        \"minutes_delayed_late_aircraft\":86457,\n        \"minutes_delayed_nas\":143513.0,\n        \"minutes_delayed_security\":304,\n        \"minutes_delayed_weather\":6207,\n        \"minutes_delayed_total\":287075\n    },\n    {\n        \"airport_code\":\"IAD\",\n        \"airport_name\":\"Washington, DC: Washington Dulles International\",\n        \"month\":\"April\",\n        \"year\":2010.0,\n        \"num_of_flights_total\":6245,\n        \"num_of_delays_carrier\":\"235\",\n        \"num_of_delays_late_aircraft\":266,\n        \"num_of_delays_nas\":191,\n        \"num_of_delays_security\":4,\n        \"num_of_delays_weather\":13,\n        \"num_of_delays_total\":710,\n        \"minutes_delayed_carrier\":13417.0,\n        \"minutes_delayed_late_aircraft\":15787,\n        \"minutes_delayed_nas\":6817.0,\n        \"minutes_delayed_security\":169,\n        \"minutes_delayed_weather\":736,\n        \"minutes_delayed_total\":36926\n    },\n    {\n        \"airport_code\":\"DEN\",\n        \"airport_name\":\"Denver, CO: Denver International\",\n        \"month\":\"April\",\n        \"year\":2010.0,\n        \"num_of_flights_total\":19059,\n        \"num_of_delays_carrier\":\"588\",\n        \"num_of_delays_late_aircraft\":1053,\n        \"num_of_delays_nas\":816,\n        \"num_of_delays_security\":11,\n        \"num_of_delays_weather\":70,\n        \"num_of_delays_total\":2537,\n        \"minutes_delayed_carrier\":33097.0,\n        \"minutes_delayed_late_aircraft\":56564,\n        \"minutes_delayed_nas\":\"NaN\",\n        \"minutes_delayed_security\":350,\n        \"minutes_delayed_weather\":4689,\n        \"minutes_delayed_total\":122726\n    },\n    {\n        \"airport_code\":\"ATL\",\n        \"airport_name\":\"Atlanta, GA: Hartsfield-Jackson Atlanta International\",\n        \"month\":\"April\",\n        \"year\":2010.0,\n        \"num_of_flights_total\":34177,\n        \"num_of_delays_carrier\":\"950\",\n        \"num_of_delays_late_aircraft\":1295,\n        \"num_of_delays_nas\":1866,\n        \"num_of_delays_security\":3,\n        \"num_of_delays_weather\":113,\n        \"num_of_delays_total\":4227,\n        \"minutes_delayed_carrier\":73349.0,\n        \"minutes_delayed_late_aircraft\":95114,\n        \"minutes_delayed_nas\":98467.0,\n        \"minutes_delayed_security\":183,\n        \"minutes_delayed_weather\":10079,\n        \"minutes_delayed_total\":277192\n    }\n]"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-2",
    "href": "250_Projects/project2.html#questiontask-2",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 2",
    "text": "Question|Task 2\nWhich airport has the worst delays? Describe the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nTo identify the worst airport for delays, I analyzed total flights, total delayed flights, the proportion of delayed flights, and average delay time. Total flights and total delayed flights provide scale and extent, while the proportion of delays and average delay time show frequency and severity. Combining these metrics, SFO emerged as the worst, with the highest proportion of delays and significant average delay times.\n\n\nplot example\n# Include and execute your code here\n\n#| label: Q2\n#| code-summary: Calculate delay metrics by airport\n\n# Group by airport and calculate required metrics\nairport_metrics = df.groupby(\"airport_code\").agg(\n    total_flights=(\"num_of_flights_total\", \"sum\"),\n    total_delayed_flights=(\"num_of_delays_total\",\"sum\"),\n    average_delay_time=(\"minutes_delayed_total\", lambda x: x.sum() / df['num_of_delays_total'].sum() / 60)\n).reset_index()\n\n# Calculate the proportion of delayed flights\nairport_metrics[\"proportion_of_delayed_flights\"] = airport_metrics[\"total_delayed_flights\"] / airport_metrics[\"total_flights\"]\n\n# Sort the aggregated metrics\nairport_metrics = airport_metrics.sort_values(by=\"proportion_of_delayed_flights\", ascending=False)\ndisplay(airport_metrics)\n\n\n\n\n\n\n\n\n\nairport_code\ntotal_flights\ntotal_delayed_flights\naverage_delay_time\nproportion_of_delayed_flights\n\n\n\n\n5\nSFO\n1630945\n425604\n0.139322\n0.260955\n\n\n3\nORD\n3597588\n830825\n0.295726\n0.230939\n\n\n0\nATL\n4430047\n902443\n0.283278\n0.203710\n\n\n2\nIAD\n851571\n168467\n0.053962\n0.197831\n\n\n4\nSAN\n917862\n175132\n0.043429\n0.190804\n\n\n1\nDEN\n2513974\n468519\n0.132096\n0.186366\n\n\n6\nSLC\n1403384\n205160\n0.053122\n0.146189"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-3",
    "href": "250_Projects/project2.html#questiontask-3",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 3",
    "text": "Question|Task 3\nWhat is the best month to fly if you want to avoid delays of any length? Describe the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nTo determine the best month to fly to avoid delays of any length, I analyzed the proportion of delayed flights for each month. The key metric I chose was the proportion of delayed flights, calculated as the total number of delayed flights divided by the total number of flights for each month. This metric is crucial as it indicates the likelihood of experiencing a delay during a given month, providing travelers with a clear picture of the best time to fly. Based on the data analysis, September is the best month to fly if you want to avoid delays. This conclusion is drawn from the lowest proportion of delayed flights during this month, ensuring a smoother travel experience for passengers.\n\n\ntable example\n# Include and execute your code here\n# display(penguins.head())\n\n#Create new column for the month\nairport_metrics = df.groupby(\"month\").agg(\n  total_flights = (\"num_of_flights_total\", \"sum\"),\n  total_delayed_flights = (\"num_of_delays_total\", \"sum\")).assign(\n  delay_flight_month = lambda x: x.total_delayed_flights / x.total_flights\n).reset_index()\n\n#Remove rows with missing values in the month column\nairport_metrics = airport_metrics[airport_metrics.month != \"NaN\"]  \n\n# Ensure the month column is ordered by month number\nairport_metrics['month'] = pd.Categorical(airport_metrics['month'], categories=[\n    'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], ordered=True)\n  \n# Sort the dataframe by month\nairport_metrics = airport_metrics.sort_values('month')\n\n#Create a chart by Plotly Express\nfig = px.bar(airport_metrics, x = \"month\", y = \"delay_flight_month\", labels={\"month\" : \"Month\", \"delay_flight_month\" : \"Average Delay Flights\"})\nfig.show()\n\n\n                                                \n\n\n\n\ntable example\n# Include and execute your code here\n# display(penguins.head())\n\n#Create new column for the month\nairport_metrics = df.groupby(\"month\").agg(\n  total_flights = (\"num_of_flights_total\", \"sum\"),\n  total_delayed_flights = (\"num_of_delays_total\", \"sum\")).assign(\n  delay_flight_month = lambda x: x.total_delayed_flights / x.total_flights\n).reset_index()\n\n#Remove rows with missing values in the month column\nairport_metrics = airport_metrics[airport_metrics.month != \"NaN\"]\n\n# Ensure the month column is ordered by month number\nairport_metrics['month'] = pd.Categorical(airport_metrics['month'], categories=[\n    'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], ordered=True)\n  \n# Sort the dataframe by month\nairport_metrics = airport_metrics.sort_values('month')\n\nfrom lets_plot import *\nimport pandas as pd\n\n# Initialize lets-plot (only needed once)\nLetsPlot.setup_html()\n\nggplot(airport_metrics) + \\\n    geom_bar(aes(x=\"month\", y=\"delay_flight_month\"), stat=\"identity\", fill=\"blue\") + \\\n    scale_x_discrete(name=\"Month\") + \\\n    scale_y_continuous(name=\"Average Delay Flights\") + \\\n    ggtitle(\"Monthly Average Delay Flights\") + \\\n    theme_minimal()\n\n\n\n            \n            \n            \n\n\n   \n   \n\n\n\n\ntable example\n# Include and execute your code here\n# display(penguins.head())\n\n#Create new column for the month\nairport_metrics = df.groupby(\"month\").agg(\n  total_flights = (\"num_of_flights_total\", \"sum\"),\n  total_delayed_flights = (\"num_of_delays_total\", \"sum\")).assign(\n  delay_flight_month = lambda x: x.total_delayed_flights / x.total_flights\n).reset_index()\n\n#Remove rows with missing values in the month column\nairport_metrics = airport_metrics[airport_metrics.month != \"NaN\"]\n  \n# Sort the dataframe by month\nairport_metrics = airport_metrics.sort_values('month')\n\nfrom lets_plot import *\nimport pandas as pd\n\n# Initialize lets-plot (only needed once)\nLetsPlot.setup_html()\n\nggplot(airport_metrics) + \\\n    geom_bar(aes(x=\"month\", y=\"delay_flight_month\"), stat=\"identity\", fill=\"blue\") + \\\n    scale_y_continuous(name=\"Average Delay Flights\") + \\\n    labs(title = \"Monthly Average Delay Flights\") +\\\n    theme_minimal() +\\\n    scale_x_discrete(name=\"Month\", limits=['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'])"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-4",
    "href": "250_Projects/project2.html#questiontask-4",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 4",
    "text": "Question|Task 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table.\nBy calculating and adding the “total_weather_delays” column, we now have a comprehensive view of both severe and mild weather-related delays, ensuring the analysis captures all aspects of weather impacts on flight schedules. This helps in making more informed decisions for better flight planning and customer experience.\n\n\ntable example\n# Include and execute your code here\n\n# Load the data from the provided URL\nurl_flights = 'https://github.com/byuidatascience/data4missing/raw/master/data-raw/flights_missing/flights_missing.json'\ndf = pd.read_json(url_flights)\n# Replace specific missing values with NaN\ndf.replace((-999, \"1500+\", \"n/a\"), (np.nan, '1500', np.nan), inplace=True)\ndf[\"num_of_delays_carrier\"] = df[\"num_of_delays_carrier\"].astype(float)\ndf.head(5)\n\n\n\n\n\n\ntable example {#cell-Q4}\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500.0\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041.0\n928.0\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\n\nJanuary\n2005.0\n12381\n414.0\n1058.0\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197.0\n2255.0\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572.0\n680.0\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n\n\n\n\n\n\n\n\n\nCalculate total weather delays\n# Replace specific missing values in 'num_of_delays_late_aircraft' with the mean\ndf['num_of_delays_late_aircraft'] = df['num_of_delays_late_aircraft'].replace(\"NaN\", np.nan).astype(float)\nlate_aircraft_mean = df['num_of_delays_late_aircraft'].mean()\ndf['num_of_delays_late_aircraft'].fillna(late_aircraft_mean, inplace=True)\n\n# Calculate total weather delays based on different delay types\ndef calculate_weather_delays(row):\n    weather_delays = row[\"num_of_delays_weather\"]\n    late_aircraft_weather_delays = 0.3 * row[\"num_of_delays_late_aircraft\"]\n    months_with_adjusted_nas = {\"April\", \"May\", \"June\", \"July\", \"August\"}\n    nas_weather_delays_factor = 0.4 if row[\"month\"] in months_with_adjusted_nas else 0.65\n    nas_weather_delays = nas_weather_delays_factor * row[\"num_of_delays_nas\"]\n    total_weather_delays = weather_delays + late_aircraft_weather_delays + nas_weather_delays\n    return total_weather_delays\n\n# Create a new column for the total weather delays\ndf[\"total_weather_delays\"] = df.apply(calculate_weather_delays, axis=1).round()\n\n# Filter to include only relevant columns for review\nfiltered_df = df[[\"airport_code\", \"num_of_delays_weather\", \"num_of_delays_late_aircraft\", \"num_of_delays_nas\", \"total_weather_delays\"]]\ndisplay(filtered_df.head(5))\n\n\n\n\n\n\n\n\n\nairport_code\nnum_of_delays_weather\nnum_of_delays_late_aircraft\nnum_of_delays_nas\ntotal_weather_delays\n\n\n\n\n0\nATL\n448\n1109.104072\n4598\n3769.0\n\n\n1\nDEN\n233\n928.000000\n935\n1119.0\n\n\n2\nIAD\n61\n1058.000000\n895\n960.0\n\n\n3\nORD\n306\n2255.000000\n5415\n4502.0\n\n\n4\nSAN\n56\n680.000000\n638\n675.0"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-5",
    "href": "250_Projects/project2.html#questiontask-5",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 5",
    "text": "Question|Task 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Describe what you learn from this graph.\nThis graph shows the proportion of flights delayed by weather at each airport. By looking at this chart, we can easily identify which airports are most affected by weather-related delays. San Francisco International (SFO) and Chicago O’Hare International (ORD) stand out with higher proportions, indicating that passengers using these airports are more likely to experience weather-related delays.\n\n\ngraph example\n# Include and execute your code here\n# display(penguins.head())\n\n#Calculate total weather delays based on different delays types\nanswer = (\n  df.groupby(\"airport_code\")\n  .agg(\n    total_flights = (\"num_of_flights_total\", \"sum\"),\n    total_delays = (\"total_weather_delays\", \"sum\")\n  )).reset_index()\n\nanswer[\"weather_proportion\"] = answer[\"total_delays\"] / answer[\"total_flights\"]\nfrom lets_plot import *\nprint(answer[\"airport_code\"],answer[\"weather_proportion\"])\n# Initialize lets-plot\nLetsPlot.setup_html()\n\n#Create a bar plot\nggplot(data=answer) + geom_bar(\n    mapping=aes(x=\"airport_code\", y=\"weather_proportion\"), \n    stat=\"identity\"\n) + labs(\n    x=\"Airport Code\", \n    y=\"Proportion of Weather Delays\", \n    title=\"Total Weather Delays by All Airports\"\n)\n\n\n0    ATL\n1    DEN\n2    IAD\n3    ORD\n4    SAN\n5    SFO\n6    SLC\nName: airport_code, dtype: object 0    0.071061\n1    0.059310\n2    0.059703\n3    0.086156\n4    0.053300\n5    0.097853\n6    0.042997\nName: weather_proportion, dtype: float64"
  },
  {
    "objectID": "250_Projects/project2.html#questiontask-6---stretch",
    "href": "250_Projects/project2.html#questiontask-6---stretch",
    "title": "Client Report - Late Flights & Missing Data",
    "section": "Question|Task 6 - Stretch",
    "text": "Question|Task 6 - Stretch\nWhich delay is the worst delay? Create a similar analysis as above for Weather Delay with: Carrier Delay and Security Delay. Compare the proportion of delay for each of the three categories in a Chart and a Table. Describe your results.\nWeather delays are the most significant, showing higher proportions compared to carrier and security delays. Airports like San Francisco International (SFO) and Chicago O’Hare International (ORD) are particularly impacted. Carrier delays also contribute, notably at San Diego International (SAN) and Washington Dulles International (IAD), but less so than weather. Security delays have the least impact across all airports. Overall, weather delays are the most challenging and frequent, making them the worst type of delay.\n\n\ntable example\n# Include and execute your code here\n\n# Prepare data for analysis\ndf_6 = df[[\"airport_code\", \"total_weather_delays\", \"num_of_delays_carrier\", \"num_of_delays_security\", \"num_of_flights_total\"]].replace(\"NaN\", np.nan)\n\ndf_6[\"num_of_delays_carrier\"] = df_6[\"num_of_delays_carrier\"].replace(np.nan, df_6[\"num_of_delays_carrier\"].astype(float).mean())\n\ndf_6[\"num_of_delays_carrier\"] = df_6[\"num_of_delays_carrier\"].astype(int)\n\n# Group by airport and calculate proportions\ntable = df_6.groupby(\"airport_code\").agg(\n  delayed_flights = (\"total_weather_delays\", \"sum\"),\n  delayed_carrier = (\"num_of_delays_carrier\", \"sum\"),\n  delayed_security = (\"num_of_delays_security\", \"sum\"),\n  total_flights = (\"num_of_flights_total\", \"sum\")\n).reset_index()\n\ntab = pd.DataFrame(table[\"airport_code\"])\ntab[\"proportion_weather\"] = table[\"delayed_flights\"] / table[\"total_flights\"]\ntab[\"proportion_carrier\"] = table[\"delayed_carrier\"] / table[\"total_flights\"]\ntab[\"proportion_security\"] = table[\"delayed_security\"] / table[\"total_flights\"]\n\ndisplay(tab.head(6))\n\n# Prepare data for plot\nweather = table[[\"airport_code\"]]\nweather[\"proportion\"] = table[\"delayed_flights\"] / table[\"total_flights\"]\ncarrier = table[[\"airport_code\"]]\ncarrier[\"proportion\"] = table[\"delayed_carrier\"] / table[\"total_flights\"]\nsecurity = table[[\"airport_code\"]]\nsecurity[\"proportion\"] = table[\"delayed_security\"] / table[\"total_flights\"]\n\n\nweather[\"category\"] = \"weather\"\ncarrier[\"category\"] = \"carrier\"\nsecurity[\"category\"] = \"security\"\n\n\ndata = pd.concat([weather, carrier, security])\n\n# Create a bar plot\nggplot(data=data)\\\n  + geom_bar(mapping=aes(x='airport_code',y='proportion', fill=\"category\"), stat=\"identity\", position=\"dodge\")\n\n\n\n\n\n\ntable example {#q6}\n\n\n\nairport_code\nproportion_weather\nproportion_carrier\nproportion_security\n\n\n\n\n0\nATL\n0.071061\n0.039068\n0.000188\n\n\n1\nDEN\n0.059310\n0.048483\n0.000392\n\n\n2\nIAD\n0.059703\n0.056086\n0.000319\n\n\n3\nORD\n0.086156\n0.040719\n0.000240\n\n\n4\nSAN\n0.053300\n0.062242\n0.000534\n\n\n5\nSFO\n0.097853\n0.052986\n0.000427"
  },
  {
    "objectID": "250_Projects/project1.html",
    "href": "250_Projects/project1.html",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "This project has some key insights. In the past, Marry and Brittany were the trendy name. Nevertheless, these days people prefer to use others. Besides, this project also shows that the famous movie does not affect the name usage.\n\n\nRead and format project 01 data\n#df = pd.read_csv(\"names_year.csv\")\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "250_Projects/project1.html#elevator-pitch",
    "href": "250_Projects/project1.html#elevator-pitch",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "This project has some key insights. In the past, Marry and Brittany were the trendy name. Nevertheless, these days people prefer to use others. Besides, this project also shows that the famous movie does not affect the name usage.\n\n\nRead and format project 01 data\n#df = pd.read_csv(\"names_year.csv\")\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "250_Projects/project1.html#questiontask-1",
    "href": "250_Projects/project1.html#questiontask-1",
    "title": "Client Report - Project 1",
    "section": "Question|Task 1",
    "text": "Question|Task 1\nHow does your name at your birth year compare to its use historically?\nIn 2002, the name Marry was less popular than in the past, especially in 1950, reaching the height of popularity with 53,791 Marry’s.\n\n\nRead, format data and visualize data as chart\nLetsPlot.setup_html()\ndf_mary = df.loc[df[\"name\"] == \"Mary\"]\nggplot(data=df_mary, mapping=aes(x=\"year\", y=\"Total\")) + geom_line() + scale_x_continuous(format=\"d\") + geom_vline(xintercept=2002, color=\"red\", linetype=\"solid\") + geom_text(x=2002, y=max(df_mary[\"Total\"]), label=\"Birth Year\", color=\"red\", ha=\"center\", va=\"bottom\")"
  },
  {
    "objectID": "250_Projects/project1.html#questiontask-2",
    "href": "250_Projects/project1.html#questiontask-2",
    "title": "Client Report - Project 1",
    "section": "Question|Task 2",
    "text": "Question|Task 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nThe chart shows that most Brittany’s were born in 1990 so if we talked to someone named Brittany on the phone, she should be 34 years old. She might not be under 20 or over 40 because that age would be too far.\n\n\nRead, format data and visualize data as chart\nLetsPlot.setup_html()\ndf_Brittany = df.loc[df[\"name\"] == \"Brittany\"]\nggplot(data=df_Brittany, mapping=aes(x=\"year\", y=\"Total\")) + geom_line() + scale_x_continuous(format=\"d\") + geom_vline(xintercept=1990, color=\"red\", linetype=\"solid\") + geom_text(x=1990, y=max(df_Brittany[\"Total\"]), label=\"Brittany's Birth Year Guess\", color=\"red\", ha=\"center\", va=\"bottom\")"
  },
  {
    "objectID": "250_Projects/project1.html#questiontask-3",
    "href": "250_Projects/project1.html#questiontask-3",
    "title": "Client Report - Project 1",
    "section": "Question|Task 3",
    "text": "Question|Task 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names in a single chart. What trends do you notice?\nIn 1950, Mary was extremely trendy compared to Martha, Peter, and Paul (53,791). The second most popular Christian name is Paul with over 24,000 the name usage. Peter and Martha are not significant with 9,690 and 7,930 respectively.\n\n\nline chart of Christian names with colors using scale_color_manual\nLetsPlot.setup_html()\ndf = df.query('year &gt; 1919 and year &lt; 2001')\ndf_Christian_names = df.loc[df[\"name\"].isin([\"Mary\", \"Martha\", \"Peter\", \"Paul\"])]\nggplot(data=df_Christian_names, mapping=aes(x=\"year\", y=\"Total\", color=\"name\")) + geom_line() + scale_color_manual(values={\"Mary\":\"red\", \"Martha\":\"blue\", \"Peter\":\"green\", \"Paul\":\"yellow\"}) + scale_x_continuous(format=\"d\")"
  },
  {
    "objectID": "250_Projects/project1.html#questiontask-4",
    "href": "250_Projects/project1.html#questiontask-4",
    "title": "Client Report - Project 1",
    "section": "Question|Task 4",
    "text": "Question|Task 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\n_In 1990, the Home Alone movie was released which was immensely popular. Nevertheless, Kevin, the name of the main character, was not affected by the use of the famous film. After 1990, there were fewer people named Kevin and it is predicted to be a downward trend for a long time.\n\n\nvisualize Kevin’s name by a line chart\nLetsPlot.setup_html()\ndf_movie_name = df.loc[df[\"name\"] == \"Kevin\"]\nggplot(data=df_movie_name, mapping=aes(x=\"year\", y=\"Total\")) + geom_line() + scale_x_continuous(format=\"d\") + geom_vline(xintercept=1990, color=\"red\", linetype=\"solid\") + geom_text(x=1990, y=max(df_movie_name[\"Total\"]), label=\"Movie's Year Released\", color=\"red\", ha=\"center\", va=\"bottom\")"
  },
  {
    "objectID": "250_Projects/project1.html#questionstretch-task",
    "href": "250_Projects/project1.html#questionstretch-task",
    "title": "Client Report - Project 1",
    "section": "Question|Stretch Task",
    "text": "Question|Stretch Task\nReproduce the chart Elliot using the data from the names_year.csv file.\n\n\nvisualize Elliot’s name by a line chart, addd a vertical line at 1982, 1985, and 2002, and change the x-axis scale to be every 10 years\nLetsPlot.setup_html()\ndf_movie_name = df.loc[df[\"name\"] == \"Elliot\"]\n(ggplot(data=df_movie_name, mapping=aes(x=\"year\", y=\"Total\", color=\"name\"))\n + geom_line()\n + scale_color_manual(values={\"Elliot\":\"blue\"})\n + scale_x_continuous(limits=[1950, 2020], breaks=[i for i in range(1950, 2021, 10)], format=\"d\")\n + geom_vline(xintercept=1982, color=\"red\", linetype=\"dashed\")\n + geom_vline(xintercept=1985, color=\"red\", linetype=\"dashed\")\n + geom_vline(xintercept=2002, color=\"red\", linetype=\"dashed\")\n + geom_text(x=1982, y=max(df_movie_name[\"Total\"]), label=\"E.T Released\", color=\"black\", ha=\"center\", va=\"bottom\", size= 5,hjust = 1, vjust = 0)\n  + geom_text(x=1985, y=max(df_movie_name[\"Total\"]), label=\"Second Released\", color=\"black\", ha=\"center\", va=\"bottom\", size= 5, hjust = 0, vjust = 1)\n  + geom_text(x=2002, y=max(df_movie_name[\"Total\"]), label=\"Third Released\", color=\"black\", ha=\"center\", va=\"bottom\", size= 5, hjust = 0, vjust = 1)\n+ labs(\n        title=\"Elliot...What?\",\n    )\n+  theme(panel_background = element_rect(fill = \"#e5ecf6\"))\n+ theme(legend_position=[1,1])\n#The first value (1) represents the x-coordinate (horizontal position).\n#The second value (1) represents the y-coordinate (vertical position).\n#Both values range from 0 to 1, where:\n#(0, 0) is the bottom-left corner.\n#(0, 1) is the top-left corner.\n#(1, 0) is the bottom-right corner.\n#(1, 1) is the top-right corner (which you are using).\n)\n\n\n\n            \n            \n            \n\n\n   \n   \n\n\n\n\nShow the code\ndf_mary = df.loc[df[\"name\"] == \"Oliver\"]\nutah_count = df_mary[\"UT\"].sum()\nprint(utah_count)\n\n\n178.0\n\n\nTesting stretch question\n\n\nShow the code\ndf_movie_name = df.loc[df[\"name\"] == \"Elliot\"]\n(\n  ggplot(data=df_movie_name, mapping=aes(x=\"year\", y=\"Total\"))\n  + geom_line(mapping=aes(color=\"name\"), size=1)\n  + scale_color_manual(values={\"Elliot\": \"blue\"})\n  + geom_vline(xintercept=1982.5, linetype=\"dashed\", color=\"red\")\n  + scale_x_continuous(format = '{}')\n  + geom_vline(xintercept=1985, linetype=\"dashed\", color=\"red\")\n  + geom_vline(xintercept=2002, linetype=\"dashed\", color=\"red\")\n  + geom_text(label=\"E.T Released\", x=1977, y=1265, size=5, color=\"black\")\n  + geom_text(label=\"Second Release\", x=1991.5, y=1265, size=5, color=\"black\")\n  + geom_text(label=\"Third Release\", x=2007.5, y=1265, size=5, color=\"black\")\n  + labs(\n        title=\"Elliot... What?\",\n        x=\"Year\",\n        y=\"Total\",\n        color=\"name\"\n    )\n  + scale_x_continuous(limits=(1950, 2025),breaks=list(range(1950,2025, 10)), format = '{}', expand=[0])\n  + scale_y_continuous(limits=(0,1300), breaks=list(range(0, 1300, 200)),format='{}')\n  + ggsize(width=800,height=380)\n  + geom_rect(xmin = 1982, xmax = 1998, ymin = 0, ymax = 35000, \n            fill = \"#843540\", alpha = 0.2, size = 0)  #to have shadow for task 2 (color the range of ages)\n)"
  },
  {
    "objectID": "250_projects.html",
    "href": "250_projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0\nProject 1\nProject 2\nProject 3\nProject 4\nProject 5\nProject 6"
  },
  {
    "objectID": "250_projects.html#repo-for-all-my-projects",
    "href": "250_projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 0\nProject 1\nProject 2\nProject 3\nProject 4\nProject 5\nProject 6"
  },
  {
    "objectID": "250_Projects/project0.html",
    "href": "250_Projects/project0.html",
    "title": "Client Report - Project 0",
    "section": "",
    "text": "THIS .qmd IS INSTRUCTIONAL AND SHOULD NOT BE USED TO WRITE YOUR REPORTS (EXCEPTION - PROJECT 0). THERE IS ANOTHER TEMPLATE FILE FOR THAT. YOU WILL NEED TO PREVIEW THE REPORT TO PRODUCE A .html FILE. YOU WILL SUBMIT THE .html FILE ON CANVAS."
  },
  {
    "objectID": "250_Projects/project0.html#elevator-pitch",
    "href": "250_Projects/project0.html#elevator-pitch",
    "title": "Client Report - Project 0",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nA SHORT (2-3 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS. (Note: this is not a summary of the project, but a summary of the results.)\nA Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4python4ds/master/data-raw/mpg/mpg.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "250_Projects/project0.html#questiontask-1",
    "href": "250_Projects/project0.html#questiontask-1",
    "title": "Client Report - Project 0",
    "section": "Question|Task 1",
    "text": "Question|Task 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\nAdd details here to answer the question but NOT like an assignment Q&A. You need to write your answers as a consulting solution report. A Client needs to understand the answer, but also needs to understand the decisions that went into the answer (when applicable).\ninclude figures in chunks and discuss your findings in the figure.\n\nYOU SHOULD HAVE QUALITY WRITING THAT DESCRIBES YOUR CHARTS AND TABLES.\nWE HIGHLY RECOMMEND GRAMMARLY TO FIX YOUR SPELLING AND GRAMMAR. WRITING TAKES TIME TO BE CLEAR. SPEND THE TIME TO PRACITCE.\nYOU SHOULD HAVE QUALITY COMMENTS THAT DESCRIBES YOUR CODES. OFTEN CODEERS WORK IN TEAMS AND YOU NEED TO HAVE QUALTIY COMMENTS FOR YOUR TEAM AND YOURSELF. YOU MAY NEED TO REVISIT CODE YOU WROTE OVER A YEAR AGO, AND IF YOU DONT COMMENT IT NOW YOU WONT REMEMBER WHY YOU DID WHAT YOU DID.\n\n\n\nRead and format data\n# Include and execute your code here"
  },
  {
    "objectID": "250_Projects/project0.html#questiontask-2",
    "href": "250_Projects/project0.html#questiontask-2",
    "title": "Client Report - Project 0",
    "section": "Question|Task 2",
    "text": "Question|Task 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\n\ninclude figures in chunks and discuss your findings in the figure.\n\n\n\nplot example\n# Include and execute your code here\npenguins = load_penguins()\n\n(\n    ggplot(data=penguins, mapping=aes(x=\"flipper_length_mm\", y=\"body_mass_g\"))\n    + geom_point(aes(color=\"species\", shape=\"species\"))\n    + geom_smooth(method=\"lm\")\n    + labs(\n        title=\"Body mass and flipper length\",\n        subtitle=\"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n        x=\"Flipper length (mm)\",\n        y=\"Body mass (g)\",\n        color=\"Species\",\n        shape=\"Species\",\n    )\n)\n\n\n\n   \n       \n       \n   \n   \n          \n   \n   \n\nMy useless chart"
  },
  {
    "objectID": "250_Projects/project0.html#questiontask-3",
    "href": "250_Projects/project0.html#questiontask-3",
    "title": "Client Report - Project 0",
    "section": "Question|Task 3",
    "text": "Question|Task 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\n\nPROVIDE TABLES THAT HELP ADDRESS THE QUESTIONS AND TASKS (IF APPLICABLE).\n\n\n\ntable example\n# Include and execute your code here\ndisplay(penguins.head())\n\n\n\n\n\n\ntable example {#cell-Q1-table}\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nNote: Non executing Python Snippets include (3) ``` followed by (3) more ```, each on their own line. These are not single quotes, they are the key left of the number 1 key on the keyboard. The top row can include the language of code that is pasted inbetween the ``` marks.\nNote: These also work in Slack and it is expected they are used for any code shared in that app. No screen shots allowed."
  },
  {
    "objectID": "250_Projects/project3.html",
    "href": "250_Projects/project3.html",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "This project delves into baseball data to uncover insights about player performance, salaries, and career longevity. By leveraging the Lahman Baseball Database, we generate SQL queries that identify top players based on batting averages and career lengths, and provide valuable metrics like average salary by position and comparisons between teams. The queries are designed to give the client actionable insights they can display on their website, with results ordered by key performance indicators such as batting average and salary. This analysis also includes visualizations, offering a comprehensive view of trends across different teams and player categories. The goal is to enhance understanding of player performance, salary distribution, and career longevity in the sport.\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\n\nSELECT DISTINCT\n  collegeplaying.playerID,  \n  salaries.salary, \n  salaries.yearID,\n  salaries.teamID,\n  collegeplaying.schoolID\n\nFROM \n  collegeplaying\n\nLEFT JOIN\n  salaries ON salaries.playerID = collegeplaying.playerID\n\nWHERE collegeplaying.schoolID = \"idbyuid\"\n\nORDER BY \n  salary DESC;\n\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nplayerID\nsalary\nyearID\nteamID\nschoolID\n\n\n\n\n0\nlindsma01\n4000000.0\n2014.0\nCHA\nidbyuid\n\n\n1\nlindsma01\n3600000.0\n2012.0\nBAL\nidbyuid\n\n\n2\nlindsma01\n2800000.0\n2011.0\nCOL\nidbyuid\n\n\n3\nlindsma01\n2300000.0\n2013.0\nCHA\nidbyuid\n\n\n4\nlindsma01\n1625000.0\n2010.0\nHOU\nidbyuid\n\n\n5\nstephga01\n1025000.0\n2001.0\nSLN\nidbyuid\n\n\n6\nstephga01\n900000.0\n2002.0\nSLN\nidbyuid\n\n\n7\nstephga01\n800000.0\n2003.0\nSLN\nidbyuid\n\n\n8\nstephga01\n550000.0\n2000.0\nSLN\nidbyuid\n\n\n9\nlindsma01\n410000.0\n2009.0\nFLO\nidbyuid\n\n\n10\nlindsma01\n395000.0\n2008.0\nFLO\nidbyuid\n\n\n11\nlindsma01\n380000.0\n2007.0\nFLO\nidbyuid\n\n\n12\nstephga01\n215000.0\n1999.0\nSLN\nidbyuid\n\n\n13\nstephga01\n185000.0\n1998.0\nPHI\nidbyuid\n\n\n14\nstephga01\n150000.0\n1997.0\nPHI\nidbyuid\n\n\n15\ncatetr01\nNaN\nNaN\nNone\nidbyuid\n\n\n\n\n\n\n\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats).\nA. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  batting.H,\n  batting.AB,\n  batting.H / batting.AB AS batting_average\n\nFROM\n  batting\n\nWHERE\n  batting.AB &gt;= 1 \n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nbatting_average\n\n\n\n\n0\naberal01\n1957\n1\n1\n1\n\n\n1\nabernte02\n1960\n1\n1\n1\n\n\n2\nabramge01\n1923\n1\n1\n1\n\n\n3\nacklefr01\n1964\n1\n1\n1\n\n\n4\nalanirj01\n2019\n1\n1\n1\n\n\n\n\n\n\n\nB. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  ROUND (CAST(batting.h AS float) / CAST(batting.ab AS float),2) AS batting_average \n\nFROM\n  batting\n\nWHERE\n  batting.ab &gt;= 10 \n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nbatting_average\n\n\n\n\n0\ncarsoma01\n2013\n0.64\n\n\n1\nnymanny01\n1974\n0.64\n\n\n2\naltizda01\n1910\n0.60\n\n\n3\njohnsde01\n1975\n0.60\n\n\n4\nsilvech01\n1948\n0.57\n\n\n\n\n\n\n\nC. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\n\nRead and format project data\n#Create a new dataframe:\n\n## Second way: ROUND (SUM(CAST(batting.h AS float)) / SUM(CAST(batting.ab AS float)),3) AS batting_average ##\n\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  batting.h,\n  batting.ab,\n  ROUND (SUM(batting.h) * 1.0 / SUM(batting.ab), 3) AS batting_average \nFROM\n  batting\n\nGROUP BY playerID\nHAVING SUM(AB) &gt;= 100\n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\nLIMIT 5\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nbatting_average\n\n\n\n\n0\ncobbty01\n1905\n36\n151\n0.366\n\n\n1\nbarnero01\n1871\n63\n157\n0.360\n\n\n2\nhornsro01\n1915\n14\n57\n0.358\n\n\n3\njacksjo01\n1908\n3\n23\n0.356\n\n\n4\nmeyerle01\n1871\n64\n130\n0.356\n\n\n\n\n\n\n\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Lets-Plot to visualize the comparison. What do you learn?\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  teams.teamID,\n  teams.yearID,\n  teams.HR,\n  teams.W,\n  salaries.teamID,\n  salaries.salary\nFROM\n  teams\nINNER JOIN\n  salaries ON salaries.teamID = teams.teamID\nWHERE\n  teams.teamID = \"BOS\" OR teams.teamID = \"CIN\"\nORDER BY\n  teams.teamID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nteamID\nyearID\nHR\nW\nteamID\nsalary\n\n\n\n\n0\nBOS\n1901\n37\n79\nBOS\n60000.0\n\n\n1\nBOS\n1901\n37\n79\nBOS\n60000.0\n\n\n2\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n3\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n4\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n233231\nCIN\n2019\n227\n75\nCIN\n14000000.0\n\n\n233232\nCIN\n2019\n227\n75\nCIN\n16445535.0\n\n\n233233\nCIN\n2019\n227\n75\nCIN\n18000000.0\n\n\n233234\nCIN\n2019\n227\n75\nCIN\n18910655.0\n\n\n233235\nCIN\n2019\n227\n75\nCIN\n20000000.0\n\n\n\n\n233236 rows × 6 columns\n\n\n\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  teamID,\n  AVG(salary) AS average_salary\nFROM\n  salaries\nWHERE\n  teamID IN ('BOS', 'CIN')\nGROUP BY\n  teamID; \n\"\"\"\ndf = pd.read_sql_query(p, conn)\nLetsPlot.setup_html()\n\n(ggplot(data=df)\n + geom_bar(mapping=aes(x='teamID',y='average_salary',fill=\"teamID\"), stat=\"identity\", xlabel=\"Team\", ylabel=\"Average Salary\", title=\"Team Average Salary Comparison\")\n + labs(title= \"Team Average Salary Comparison\", x= \"Team\", y =\"Average Salary\"))\n\n\n\n            \n            \n            \n\n\n   \n   \n\n\nSTRETCH QUESTIONS 1. Advanced Salary Distribution by Position (with Case Statement)\n\n\nRead and format project data\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  fieldingpost.playerID,\n  COALESCE(MAX(salaries.salary), 'N/A') AS highest_salary,\n  AVG(salaries.salary) AS avg_salary,\n  COUNT(DISTINCT fieldingpost.playerID) AS total_players,\n  fieldingpost.POS,\n  salaries.teamID,\n  CASE\n    WHEN AVG(salaries.salary) &gt;= 1000000 THEN 'High Salary'\n    WHEN AVG(salaries.salary) &gt;= 500000 AND AVG(salaries.salary) &lt; 1000000 THEN 'Medium Salary'\n    ELSE 'Low Salary'\n  END AS salary_category\nFROM\n  fieldingpost\nLEFT JOIN\n  salaries ON salaries.playerID = fieldingpost.playerID\nGROUP BY\n  fieldingpost.POS\nORDER BY\n  avg_salary DESC\nLIMIT 10;\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(10)\n\n\n\n\n\n\n\n\n\nplayerID\nhighest_salary\navg_salary\ntotal_players\nPOS\nteamID\nsalary_category\n\n\n\n\n0\ncabremi01\n28000000.0\n4.714455e+06\n360\n1B\nDET\nHigh Salary\n\n\n1\nrodrial01\n33000000.0\n4.288380e+06\n296\nSS\nNYA\nHigh Salary\n\n\n2\nrodrial01\n33000000.0\n4.257195e+06\n366\n3B\nNYA\nHigh Salary\n\n\n3\ncabremi01\n28000000.0\n4.237139e+06\n498\nRF\nDET\nHigh Salary\n\n\n4\ncespeyo01\n27328046.0\n3.999224e+06\n372\nCF\nNYN\nHigh Salary\n\n\n5\ncabremi01\n28000000.0\n3.963197e+06\n525\nLF\nDET\nHigh Salary\n\n\n6\nkershcl01\n33000000.0\n3.598436e+06\n1796\nP\nLAN\nHigh Salary\n\n\n7\nmauerjo01\n23000000.0\n2.958648e+06\n348\nC\nMIN\nHigh Salary\n\n\n8\ncanoro01\n24000000.0\n2.914565e+06\n352\n2B\nSEA\nHigh Salary\n\n\n\n\n\n\n\n2. Advanced Career Longevity and Performance (with Subqueries)\n\n\nRead and format project data\nimport sqlite3\nimport pandas as pd\n\n# Connect to the SQLite database\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\n\n# First query: Calculate the average career length\np1 = \"\"\"\nWITH CareerLength AS (\n    -- Calculate career length (max yearID - min yearID) for each player\n    SELECT\n        playerID,\n        MIN(yearID) AS first_year,\n        MAX(yearID) AS last_year,\n        (MAX(yearID) - MIN(yearID)) AS career_length\n    FROM\n        Batting\n    GROUP BY\n        playerID\n    HAVING\n        COUNT(yearID) &gt; 0 -- Ensuring the player has played at least one game\n)\n-- Calculate the average career length for all players\nSELECT\n    AVG(career_length) AS average_career_length\nFROM\n    CareerLength;\n\"\"\"\n\n# Execute the first query and store the result\navg_career_length_df = pd.read_sql_query(p1, conn)\nprint(avg_career_length_df)\n\n\n   average_career_length\n0               4.717101\n\n\n\n\nShow the code\n# Second query: Get the top 10 players with the longest careers\np2 = \"\"\"\nWITH CareerLength AS (\n    -- Calculate career length (max yearID - min yearID) for each player\n    SELECT\n        playerID,\n        MIN(yearID) AS first_year,\n        MAX(yearID) AS last_year,\n        (MAX(yearID) - MIN(yearID)) AS career_length\n    FROM\n        Batting\n    GROUP BY\n        playerID\n    HAVING\n        COUNT(yearID) &gt; 0 -- Ensuring the player has played at least one game\n)\n-- Fetch the top 10 players with the longest careers\nSELECT\n    c.playerID,\n    p.nameFirst AS first_name,\n    p.nameLast AS last_name,\n    c.career_length\nFROM\n    CareerLength c\nJOIN\n    People p ON c.playerID = p.playerID -- Use the correct 'People' table instead of 'MASTER'\nORDER BY\n    c.career_length DESC\nLIMIT 10;\n\"\"\"\n\n# Execute the second query and store the result\ntop_10_players_df = pd.read_sql_query(p2, conn)\nprint(top_10_players_df)\n\n# Close the database connection\nconn.close()\n\n\n    playerID first_name last_name  career_length\n0  altroni01       Nick   Altrock             35\n1  orourji01        Jim  O'Rourke             32\n2  minosmi01     Minnie    Minoso             31\n3  olearch01    Charley   O'Leary             30\n4  lathaar01      Arlie    Latham             29\n5  mcguide01     Deacon   McGuire             28\n6  eversjo01     Johnny     Evers             27\n7  jennihu01     Hughie  Jennings             27\n8   ryanno01      Nolan      Ryan             27\n9  streega01      Gabby    Street             27\n\n\nMethod checkpoint\n\n\nShow the code\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\n\n\nSELECT \n  H,\n  AB,\n  playerID,\n  H*1.0/AB AS batting_average\n\nFROM \n  batting\nLIMIT 2;\n\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nH\nAB\nplayerID\nbatting_average\n\n\n\n\n0\n0\n4\nabercda01\n0.000000\n\n\n1\n32\n118\naddybo01\n0.271186"
  },
  {
    "objectID": "250_Projects/project3.html#elevator-pitch",
    "href": "250_Projects/project3.html#elevator-pitch",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "This project delves into baseball data to uncover insights about player performance, salaries, and career longevity. By leveraging the Lahman Baseball Database, we generate SQL queries that identify top players based on batting averages and career lengths, and provide valuable metrics like average salary by position and comparisons between teams. The queries are designed to give the client actionable insights they can display on their website, with results ordered by key performance indicators such as batting average and salary. This analysis also includes visualizations, offering a comprehensive view of trends across different teams and player categories. The goal is to enhance understanding of player performance, salary distribution, and career longevity in the sport.\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\n\nSELECT DISTINCT\n  collegeplaying.playerID,  \n  salaries.salary, \n  salaries.yearID,\n  salaries.teamID,\n  collegeplaying.schoolID\n\nFROM \n  collegeplaying\n\nLEFT JOIN\n  salaries ON salaries.playerID = collegeplaying.playerID\n\nWHERE collegeplaying.schoolID = \"idbyuid\"\n\nORDER BY \n  salary DESC;\n\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nplayerID\nsalary\nyearID\nteamID\nschoolID\n\n\n\n\n0\nlindsma01\n4000000.0\n2014.0\nCHA\nidbyuid\n\n\n1\nlindsma01\n3600000.0\n2012.0\nBAL\nidbyuid\n\n\n2\nlindsma01\n2800000.0\n2011.0\nCOL\nidbyuid\n\n\n3\nlindsma01\n2300000.0\n2013.0\nCHA\nidbyuid\n\n\n4\nlindsma01\n1625000.0\n2010.0\nHOU\nidbyuid\n\n\n5\nstephga01\n1025000.0\n2001.0\nSLN\nidbyuid\n\n\n6\nstephga01\n900000.0\n2002.0\nSLN\nidbyuid\n\n\n7\nstephga01\n800000.0\n2003.0\nSLN\nidbyuid\n\n\n8\nstephga01\n550000.0\n2000.0\nSLN\nidbyuid\n\n\n9\nlindsma01\n410000.0\n2009.0\nFLO\nidbyuid\n\n\n10\nlindsma01\n395000.0\n2008.0\nFLO\nidbyuid\n\n\n11\nlindsma01\n380000.0\n2007.0\nFLO\nidbyuid\n\n\n12\nstephga01\n215000.0\n1999.0\nSLN\nidbyuid\n\n\n13\nstephga01\n185000.0\n1998.0\nPHI\nidbyuid\n\n\n14\nstephga01\n150000.0\n1997.0\nPHI\nidbyuid\n\n\n15\ncatetr01\nNaN\nNaN\nNone\nidbyuid\n\n\n\n\n\n\n\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats).\nA. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  batting.H,\n  batting.AB,\n  batting.H / batting.AB AS batting_average\n\nFROM\n  batting\n\nWHERE\n  batting.AB &gt;= 1 \n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nbatting_average\n\n\n\n\n0\naberal01\n1957\n1\n1\n1\n\n\n1\nabernte02\n1960\n1\n1\n1\n\n\n2\nabramge01\n1923\n1\n1\n1\n\n\n3\nacklefr01\n1964\n1\n1\n1\n\n\n4\nalanirj01\n2019\n1\n1\n1\n\n\n\n\n\n\n\nB. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  ROUND (CAST(batting.h AS float) / CAST(batting.ab AS float),2) AS batting_average \n\nFROM\n  batting\n\nWHERE\n  batting.ab &gt;= 10 \n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nbatting_average\n\n\n\n\n0\ncarsoma01\n2013\n0.64\n\n\n1\nnymanny01\n1974\n0.64\n\n\n2\naltizda01\n1910\n0.60\n\n\n3\njohnsde01\n1975\n0.60\n\n\n4\nsilvech01\n1948\n0.57\n\n\n\n\n\n\n\nC. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\n\nRead and format project data\n#Create a new dataframe:\n\n## Second way: ROUND (SUM(CAST(batting.h AS float)) / SUM(CAST(batting.ab AS float)),3) AS batting_average ##\n\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  batting.playerID,\n  batting.yearID,\n  batting.h,\n  batting.ab,\n  ROUND (SUM(batting.h) * 1.0 / SUM(batting.ab), 3) AS batting_average \nFROM\n  batting\n\nGROUP BY playerID\nHAVING SUM(AB) &gt;= 100\n\nORDER BY\n  batting_average DESC,\n  batting.playerID ASC\n\nLIMIT 5\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(5)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nbatting_average\n\n\n\n\n0\ncobbty01\n1905\n36\n151\n0.366\n\n\n1\nbarnero01\n1871\n63\n157\n0.360\n\n\n2\nhornsro01\n1915\n14\n57\n0.358\n\n\n3\njacksjo01\n1908\n3\n23\n0.356\n\n\n4\nmeyerle01\n1871\n64\n130\n0.356\n\n\n\n\n\n\n\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Lets-Plot to visualize the comparison. What do you learn?\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  teams.teamID,\n  teams.yearID,\n  teams.HR,\n  teams.W,\n  salaries.teamID,\n  salaries.salary\nFROM\n  teams\nINNER JOIN\n  salaries ON salaries.teamID = teams.teamID\nWHERE\n  teams.teamID = \"BOS\" OR teams.teamID = \"CIN\"\nORDER BY\n  teams.teamID ASC\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nteamID\nyearID\nHR\nW\nteamID\nsalary\n\n\n\n\n0\nBOS\n1901\n37\n79\nBOS\n60000.0\n\n\n1\nBOS\n1901\n37\n79\nBOS\n60000.0\n\n\n2\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n3\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n4\nBOS\n1901\n37\n79\nBOS\n62500.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n233231\nCIN\n2019\n227\n75\nCIN\n14000000.0\n\n\n233232\nCIN\n2019\n227\n75\nCIN\n16445535.0\n\n\n233233\nCIN\n2019\n227\n75\nCIN\n18000000.0\n\n\n233234\nCIN\n2019\n227\n75\nCIN\n18910655.0\n\n\n233235\nCIN\n2019\n227\n75\nCIN\n20000000.0\n\n\n\n\n233236 rows × 6 columns\n\n\n\n\n\nRead and format project data\n#Create a new dataframe:\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  teamID,\n  AVG(salary) AS average_salary\nFROM\n  salaries\nWHERE\n  teamID IN ('BOS', 'CIN')\nGROUP BY\n  teamID; \n\"\"\"\ndf = pd.read_sql_query(p, conn)\nLetsPlot.setup_html()\n\n(ggplot(data=df)\n + geom_bar(mapping=aes(x='teamID',y='average_salary',fill=\"teamID\"), stat=\"identity\", xlabel=\"Team\", ylabel=\"Average Salary\", title=\"Team Average Salary Comparison\")\n + labs(title= \"Team Average Salary Comparison\", x= \"Team\", y =\"Average Salary\"))\n\n\n\n            \n            \n            \n\n\n   \n   \n\n\nSTRETCH QUESTIONS 1. Advanced Salary Distribution by Position (with Case Statement)\n\n\nRead and format project data\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\nSELECT\n  fieldingpost.playerID,\n  COALESCE(MAX(salaries.salary), 'N/A') AS highest_salary,\n  AVG(salaries.salary) AS avg_salary,\n  COUNT(DISTINCT fieldingpost.playerID) AS total_players,\n  fieldingpost.POS,\n  salaries.teamID,\n  CASE\n    WHEN AVG(salaries.salary) &gt;= 1000000 THEN 'High Salary'\n    WHEN AVG(salaries.salary) &gt;= 500000 AND AVG(salaries.salary) &lt; 1000000 THEN 'Medium Salary'\n    ELSE 'Low Salary'\n  END AS salary_category\nFROM\n  fieldingpost\nLEFT JOIN\n  salaries ON salaries.playerID = fieldingpost.playerID\nGROUP BY\n  fieldingpost.POS\nORDER BY\n  avg_salary DESC\nLIMIT 10;\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf.head(10)\n\n\n\n\n\n\n\n\n\nplayerID\nhighest_salary\navg_salary\ntotal_players\nPOS\nteamID\nsalary_category\n\n\n\n\n0\ncabremi01\n28000000.0\n4.714455e+06\n360\n1B\nDET\nHigh Salary\n\n\n1\nrodrial01\n33000000.0\n4.288380e+06\n296\nSS\nNYA\nHigh Salary\n\n\n2\nrodrial01\n33000000.0\n4.257195e+06\n366\n3B\nNYA\nHigh Salary\n\n\n3\ncabremi01\n28000000.0\n4.237139e+06\n498\nRF\nDET\nHigh Salary\n\n\n4\ncespeyo01\n27328046.0\n3.999224e+06\n372\nCF\nNYN\nHigh Salary\n\n\n5\ncabremi01\n28000000.0\n3.963197e+06\n525\nLF\nDET\nHigh Salary\n\n\n6\nkershcl01\n33000000.0\n3.598436e+06\n1796\nP\nLAN\nHigh Salary\n\n\n7\nmauerjo01\n23000000.0\n2.958648e+06\n348\nC\nMIN\nHigh Salary\n\n\n8\ncanoro01\n24000000.0\n2.914565e+06\n352\n2B\nSEA\nHigh Salary\n\n\n\n\n\n\n\n2. Advanced Career Longevity and Performance (with Subqueries)\n\n\nRead and format project data\nimport sqlite3\nimport pandas as pd\n\n# Connect to the SQLite database\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\n\n# First query: Calculate the average career length\np1 = \"\"\"\nWITH CareerLength AS (\n    -- Calculate career length (max yearID - min yearID) for each player\n    SELECT\n        playerID,\n        MIN(yearID) AS first_year,\n        MAX(yearID) AS last_year,\n        (MAX(yearID) - MIN(yearID)) AS career_length\n    FROM\n        Batting\n    GROUP BY\n        playerID\n    HAVING\n        COUNT(yearID) &gt; 0 -- Ensuring the player has played at least one game\n)\n-- Calculate the average career length for all players\nSELECT\n    AVG(career_length) AS average_career_length\nFROM\n    CareerLength;\n\"\"\"\n\n# Execute the first query and store the result\navg_career_length_df = pd.read_sql_query(p1, conn)\nprint(avg_career_length_df)\n\n\n   average_career_length\n0               4.717101\n\n\n\n\nShow the code\n# Second query: Get the top 10 players with the longest careers\np2 = \"\"\"\nWITH CareerLength AS (\n    -- Calculate career length (max yearID - min yearID) for each player\n    SELECT\n        playerID,\n        MIN(yearID) AS first_year,\n        MAX(yearID) AS last_year,\n        (MAX(yearID) - MIN(yearID)) AS career_length\n    FROM\n        Batting\n    GROUP BY\n        playerID\n    HAVING\n        COUNT(yearID) &gt; 0 -- Ensuring the player has played at least one game\n)\n-- Fetch the top 10 players with the longest careers\nSELECT\n    c.playerID,\n    p.nameFirst AS first_name,\n    p.nameLast AS last_name,\n    c.career_length\nFROM\n    CareerLength c\nJOIN\n    People p ON c.playerID = p.playerID -- Use the correct 'People' table instead of 'MASTER'\nORDER BY\n    c.career_length DESC\nLIMIT 10;\n\"\"\"\n\n# Execute the second query and store the result\ntop_10_players_df = pd.read_sql_query(p2, conn)\nprint(top_10_players_df)\n\n# Close the database connection\nconn.close()\n\n\n    playerID first_name last_name  career_length\n0  altroni01       Nick   Altrock             35\n1  orourji01        Jim  O'Rourke             32\n2  minosmi01     Minnie    Minoso             31\n3  olearch01    Charley   O'Leary             30\n4  lathaar01      Arlie    Latham             29\n5  mcguide01     Deacon   McGuire             28\n6  eversjo01     Johnny     Evers             27\n7  jennihu01     Hughie  Jennings             27\n8   ryanno01      Nolan      Ryan             27\n9  streega01      Gabby    Street             27\n\n\nMethod checkpoint\n\n\nShow the code\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\np = \"\"\"\n\n\nSELECT \n  H,\n  AB,\n  playerID,\n  H*1.0/AB AS batting_average\n\nFROM \n  batting\nLIMIT 2;\n\n\"\"\"\ndf = pd.read_sql_query(p, conn)\ndf\n\n\n\n\n\n\n\n\n\nH\nAB\nplayerID\nbatting_average\n\n\n\n\n0\n0\n4\nabercda01\n0.000000\n\n\n1\n32\n118\naddybo01\n0.271186"
  }
]